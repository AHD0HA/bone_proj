{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152e8827-62b0-4a9d-bf2c-658a616453dd",
   "metadata": {},
   "source": [
    "#### 기본 정보\n",
    "- 서울대학교병원 (56032명, 154411건 데이터)\n",
    "- 442*512사이즈 png ~~512\\*512 사이즈 png~~\n",
    "- -score상 골다공증 기준 (-2.5 이하인 경우에 골다공증)\n",
    "    - L1-L4 T-Score', 'Neck T-Score', 'Total T-Score' 중 가장 낮은 값 기준 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea75d07-c051-42d6-ac51-ac9d5cd0e066",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Binary Classificaiton 구성\n",
    "1. csv 전처리\n",
    "2. 데이터 분할\n",
    "3. Dataset 생성\n",
    "4. 모델 구축\n",
    "5. 학습 및 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab43b63f-0b70-452b-b92c-d90989638d5d",
   "metadata": {},
   "source": [
    "#### 고민\n",
    "- 같은 사람 사진은 하나만 사용해야할까?\n",
    "- trian 데이터 수 늘려보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02229f86-946d-4b64-80ad-4edb2b25d9c7",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2251891-7096-42e9-be95-3c3d23f5954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "647c136e-651f-4f9d-928e-02ffc3cc7d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_208/2037917953.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./data/Train_SNUH_CPA_90d_osteo_2class.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Train_SNUH_CPA_90d_osteo_2class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c56a035-a572-4c70-8926-9920ee0f0f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>fp</th>\n",
       "      <th>label</th>\n",
       "      <th>cxr_StudyDate</th>\n",
       "      <th>L1-L4 T-Score</th>\n",
       "      <th>Neck T-Score</th>\n",
       "      <th>Total T-Score</th>\n",
       "      <th>dxa_StudyDate</th>\n",
       "      <th>cxr_dxa_diff</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>PatientBirthDate</th>\n",
       "      <th>PatientSex</th>\n",
       "      <th>PatientSize</th>\n",
       "      <th>PatientWeight</th>\n",
       "      <th>연구별 환자 ID</th>\n",
       "      <th>최종수진일</th>\n",
       "      <th>org_dir</th>\n",
       "      <th>PathToFolder</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32764659</td>\n",
       "      <td>10000089_32764659_20090113_1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32764659_2009-01-13 00:00:00</td>\n",
       "      <td>19411220.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.52</td>\n",
       "      <td>58.4</td>\n",
       "      <td>R-1414-00035092</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>part1</td>\n",
       "      <td>10000089_32764659_20090113</td>\n",
       "      <td>1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38248009</td>\n",
       "      <td>10000451_38248009_20090113_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2008-11-24</td>\n",
       "      <td>50.0</td>\n",
       "      <td>38248009_2009-01-13 00:00:00</td>\n",
       "      <td>19460806.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.56</td>\n",
       "      <td>60.9</td>\n",
       "      <td>R-1414-00051293</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>part1</td>\n",
       "      <td>10000451_38248009_20090113</td>\n",
       "      <td>1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38522783</td>\n",
       "      <td>10000477_38522783_20090113_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38522783_2009-01-13 00:00:00</td>\n",
       "      <td>19550225.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.55</td>\n",
       "      <td>56.5</td>\n",
       "      <td>R-1414-00052208</td>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>part1</td>\n",
       "      <td>10000477_38522783_20090113</td>\n",
       "      <td>1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32369960</td>\n",
       "      <td>10000753_32369960_20090113_1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32369960_2009-01-13 00:00:00</td>\n",
       "      <td>19590102.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.65</td>\n",
       "      <td>63.7</td>\n",
       "      <td>R-1414-00033931</td>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>part1</td>\n",
       "      <td>10000753_32369960_20090113</td>\n",
       "      <td>1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33532709</td>\n",
       "      <td>10000791_33532709_20090113_1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2009-03-30</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>33532709_2009-01-13 00:00:00</td>\n",
       "      <td>19430423.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.60</td>\n",
       "      <td>51.4</td>\n",
       "      <td>R-1414-00037346</td>\n",
       "      <td>2013-09-17</td>\n",
       "      <td>part1</td>\n",
       "      <td>10000791_33532709_20090113</td>\n",
       "      <td>1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154406</th>\n",
       "      <td>49245327</td>\n",
       "      <td>997333777_49245327_20170530_1.2.840.113619.2.2...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>42.0</td>\n",
       "      <td>49245327_2017-05-30 00:00:00</td>\n",
       "      <td>19420820.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.62</td>\n",
       "      <td>56.6</td>\n",
       "      <td>R-1414-00079059</td>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>part2</td>\n",
       "      <td>997333777_49245327_20170530</td>\n",
       "      <td>1.2.840.113619.2.203.4.2147483647.1496124728.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154407</th>\n",
       "      <td>49245327</td>\n",
       "      <td>997901553_49245327_20170531_1.3.46.670589.26.8...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49245327_2017-05-31 00:00:00</td>\n",
       "      <td>19420820.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.62</td>\n",
       "      <td>56.6</td>\n",
       "      <td>R-1414-00079059</td>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>part2</td>\n",
       "      <td>997901553_49245327_20170531</td>\n",
       "      <td>1.3.46.670589.26.802065.4.20170531.64800.21563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154408</th>\n",
       "      <td>49245327</td>\n",
       "      <td>998914752_49245327_20170531_1.3.46.670589.26.8...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49245327_2017-05-31 00:00:00</td>\n",
       "      <td>19420820.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.62</td>\n",
       "      <td>56.6</td>\n",
       "      <td>R-1414-00079059</td>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>part2</td>\n",
       "      <td>998914752_49245327_20170531</td>\n",
       "      <td>1.3.46.670589.26.802065.4.20170531.171542.2160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154409</th>\n",
       "      <td>49415652</td>\n",
       "      <td>999035654_49415652_20170531_1.3.46.670589.26.8...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>16.0</td>\n",
       "      <td>49415652_2017-05-31 00:00:00</td>\n",
       "      <td>19520301.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.54</td>\n",
       "      <td>79.3</td>\n",
       "      <td>R-1414-00079348</td>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>part2</td>\n",
       "      <td>999035654_49415652_20170531</td>\n",
       "      <td>1.3.46.670589.26.802065.4.20170531.182754.2160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154410</th>\n",
       "      <td>49245327</td>\n",
       "      <td>999279752_49245327_20170601_1.3.46.670589.26.8...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>44.0</td>\n",
       "      <td>49245327_2017-06-01 00:00:00</td>\n",
       "      <td>19420820.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.62</td>\n",
       "      <td>56.6</td>\n",
       "      <td>R-1414-00079059</td>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>part2</td>\n",
       "      <td>999279752_49245327_20170601</td>\n",
       "      <td>1.3.46.670589.26.802065.4.20170601.64222.21618...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154411 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pid                                                 fp  label  \\\n",
       "0       32764659                   10000089_32764659_20090113_1.png      0   \n",
       "1       38248009                   10000451_38248009_20090113_1.png      1   \n",
       "2       38522783                   10000477_38522783_20090113_1.png      1   \n",
       "3       32369960                   10000753_32369960_20090113_1.png      0   \n",
       "4       33532709                   10000791_33532709_20090113_1.png      0   \n",
       "...          ...                                                ...    ...   \n",
       "154406  49245327  997333777_49245327_20170530_1.2.840.113619.2.2...      0   \n",
       "154407  49245327  997901553_49245327_20170531_1.3.46.670589.26.8...      0   \n",
       "154408  49245327  998914752_49245327_20170531_1.3.46.670589.26.8...      0   \n",
       "154409  49415652  999035654_49415652_20170531_1.3.46.670589.26.8...      0   \n",
       "154410  49245327  999279752_49245327_20170601_1.3.46.670589.26.8...      0   \n",
       "\n",
       "       cxr_StudyDate  L1-L4 T-Score  Neck T-Score  Total T-Score  \\\n",
       "0         2009-01-13           -1.0          -0.5            0.1   \n",
       "1         2009-01-13           -3.2           0.2           -0.2   \n",
       "2         2009-01-13           -2.5          -2.6           -2.1   \n",
       "3         2009-01-13            0.8           0.9            0.8   \n",
       "4         2009-01-13           -2.4          -2.1           -1.7   \n",
       "...              ...            ...           ...            ...   \n",
       "154406    2017-05-30            3.7           0.7            1.7   \n",
       "154407    2017-05-31            3.7           0.7            1.7   \n",
       "154408    2017-05-31            3.7           0.7            1.7   \n",
       "154409    2017-05-31            2.7           1.4            1.2   \n",
       "154410    2017-06-01            3.7           0.7            1.7   \n",
       "\n",
       "       dxa_StudyDate  cxr_dxa_diff                       StudyID  \\\n",
       "0         2009-01-13           0.0  32764659_2009-01-13 00:00:00   \n",
       "1         2008-11-24          50.0  38248009_2009-01-13 00:00:00   \n",
       "2         2009-01-12           1.0  38522783_2009-01-13 00:00:00   \n",
       "3         2009-01-13           0.0  32369960_2009-01-13 00:00:00   \n",
       "4         2009-03-30         -76.0  33532709_2009-01-13 00:00:00   \n",
       "...              ...           ...                           ...   \n",
       "154406    2017-04-18          42.0  49245327_2017-05-30 00:00:00   \n",
       "154407    2017-04-18          43.0  49245327_2017-05-31 00:00:00   \n",
       "154408    2017-04-18          43.0  49245327_2017-05-31 00:00:00   \n",
       "154409    2017-05-15          16.0  49415652_2017-05-31 00:00:00   \n",
       "154410    2017-04-18          44.0  49245327_2017-06-01 00:00:00   \n",
       "\n",
       "        PatientBirthDate PatientSex  PatientSize  PatientWeight  \\\n",
       "0             19411220.0          F         1.52           58.4   \n",
       "1             19460806.0          F         1.56           60.9   \n",
       "2             19550225.0          F         1.55           56.5   \n",
       "3             19590102.0          F         1.65           63.7   \n",
       "4             19430423.0          M         1.60           51.4   \n",
       "...                  ...        ...          ...            ...   \n",
       "154406        19420820.0          M         1.62           56.6   \n",
       "154407        19420820.0          M         1.62           56.6   \n",
       "154408        19420820.0          M         1.62           56.6   \n",
       "154409        19520301.0          F         1.54           79.3   \n",
       "154410        19420820.0          M         1.62           56.6   \n",
       "\n",
       "              연구별 환자 ID       최종수진일 org_dir                 PathToFolder  \\\n",
       "0       R-1414-00035092  2017-09-18   part1   10000089_32764659_20090113   \n",
       "1       R-1414-00051293  2016-10-27   part1   10000451_38248009_20090113   \n",
       "2       R-1414-00052208  2025-04-08   part1   10000477_38522783_20090113   \n",
       "3       R-1414-00033931  2025-03-31   part1   10000753_32369960_20090113   \n",
       "4       R-1414-00037346  2013-09-17   part1   10000791_33532709_20090113   \n",
       "...                 ...         ...     ...                          ...   \n",
       "154406  R-1414-00079059  2017-09-19   part2  997333777_49245327_20170530   \n",
       "154407  R-1414-00079059  2017-09-19   part2  997901553_49245327_20170531   \n",
       "154408  R-1414-00079059  2017-09-19   part2  998914752_49245327_20170531   \n",
       "154409  R-1414-00079348  2018-06-27   part2  999035654_49415652_20170531   \n",
       "154410  R-1414-00079059  2017-09-19   part2  999279752_49245327_20170601   \n",
       "\n",
       "                                                 FileName  \n",
       "0                                                   1.dcm  \n",
       "1                                                   1.dcm  \n",
       "2                                                   1.dcm  \n",
       "3                                                   1.dcm  \n",
       "4                                                   1.dcm  \n",
       "...                                                   ...  \n",
       "154406  1.2.840.113619.2.203.4.2147483647.1496124728.7...  \n",
       "154407  1.3.46.670589.26.802065.4.20170531.64800.21563...  \n",
       "154408  1.3.46.670589.26.802065.4.20170531.171542.2160...  \n",
       "154409  1.3.46.670589.26.802065.4.20170531.182754.2160...  \n",
       "154410  1.3.46.670589.26.802065.4.20170601.64222.21618...  \n",
       "\n",
       "[154411 rows x 19 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf7c4b-347d-416c-bb46-5fc6138647f2",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91c3b54a-4070-4290-b2f6-61ab8c7edb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환자 수: 56032\n"
     ]
    }
   ],
   "source": [
    "unique_pids = df['pid'].unique()\n",
    "print(f'환자 수: {len(unique_pids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bdf1ca7-2281-49e1-8cf8-9875aafdf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_pids, temp_pids = train_test_split(unique_pids, test_size=0.2, random_state=42)\n",
    "val_pids, test_pids = train_test_split(temp_pids, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cca3aaf7-54db-4bd5-8b32-e8d123725015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['pid'].isin(train_pids)].copy()\n",
    "df_val = df[df['pid'].isin(val_pids)].copy()\n",
    "df_test = df[df['pid'].isin(test_pids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a22405c5-cf60-4f6e-9e35-e5ddc8141e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "샘플 수: 123434\n",
      "환자 수: 44825\n",
      "라벨 분포: {0: 0.7972033637409466, 1: 0.20279663625905342}\n",
      "\n",
      "val\n",
      "샘플 수: 15385\n",
      "환자 수: 5603\n",
      "라벨 분포: {0: 0.8085147871303218, 1: 0.19148521286967826}\n",
      "\n",
      "test\n",
      "샘플 수: 15592\n",
      "환자 수: 5604\n",
      "라벨 분포: {0: 0.8001539250897897, 1: 0.19984607491021036}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def describe_split(name, df):\n",
    "    print(f'{name}')\n",
    "    print(f'샘플 수: {len(df)}')\n",
    "    print(f'환자 수: {df['pid'].nunique()}')\n",
    "    print(f'라벨 분포: {df['label'].value_counts(normalize=True).to_dict()}\\n')\n",
    "\n",
    "describe_split('train', df_train)\n",
    "describe_split('val', df_val)\n",
    "describe_split('test', df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9925d09d-48c2-427f-b611-d6af443b936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('data/train.csv', index=False)\n",
    "df_val.to_csv('data/val.csv', index=False)\n",
    "df_test.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f1da5-78d4-4588-98c8-ca85a4c1affd",
   "metadata": {},
   "source": [
    "## 데이터셋 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b8ace-1402-4aad-82bf-4717f53aa24f",
   "metadata": {},
   "source": [
    "### 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3333bd2f-8571-4b4c-bdfb-607beb798acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "#데이터셋 클래스 정의\n",
    "class CXRDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True) #어떤 df를 넣어도 문제없도록.\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx): #dataset loader에서 텐서형태로 꺼낼 수 있도록 정의해야 함. \n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.base_path, row['fp'])\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform: #transform.compose()객체를 받으면 해당 작업들이 들어 있음.\n",
    "            image = self.transform(image)\n",
    "        return image, int(row['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6b98b-1d5a-4902-ba6a-c12e4d3cbfa9",
   "metadata": {},
   "source": [
    "### 데이터셋 로더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0795896-34b1-4819-bed6-2b8d1bb4ba15",
   "metadata": {},
   "source": [
    "#### transform 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0d301142-5716-4d44-97a6-44e5e1d675bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5], std = [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8db05e-0e2c-473f-9018-2752f6743441",
   "metadata": {},
   "source": [
    "#### Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7d0b4ee-9aca-4b2c-a43b-c0e21facc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data/SNUH_CXR_png/SNUH_CXR_png'\n",
    "\n",
    "train_dataset = CXRDataset(df_train, base_path, transform=transform)\n",
    "val_dataset = CXRDataset(df_val, base_path, transform=transform)\n",
    "test_dataset = CXRDataset(df_test, base_path, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa25ed-8a13-4cdb-af00-6fc6e7bf52f5",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a07c3c3-a88b-4e8e-aaec-972f053ce1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16 #몇으로 하는게 좋을까\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, pin_memory=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d0da7ca-c804-47dd-bd42-20fb60ad09c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 shape:  torch.Size([16, 1, 256, 256])\n",
      "라벨 shape: tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print('이미지 shape: ', images.shape)\n",
    "print('라벨 shape:', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9dd48-0340-4039-a9da-c394f7ef79ce",
   "metadata": {},
   "source": [
    "## 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89d93efb-e613-4732-92b5-e3ab163d3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    #레이어들을 정의\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1) \n",
    "\n",
    "        self.fc1 = nn.Linear(32*64*64, 128) \n",
    "        self.fc2 = nn.Linear(128,1)\n",
    "\n",
    "    #레이어를 쌓아 모델을 정의\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))               \n",
    "        x = self.fc2(x)                       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72c047ff-d177-489a-9764-553d331afbbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=131072, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b8e55-0209-4423-aa44-e19a2595c526",
   "metadata": {},
   "source": [
    "## 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f34bc311-95a8-42d3-ab1c-025ffe6ea062",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  🔄 Epoch 1 시작\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n",
      "    ✅ forward 완료\n",
      "    ✅ loss 계산 완료\n",
      "    ✅ backward 완료, optimizer step 완료\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#print(f\"    📦 배치 불러오기 완료\")\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[41], line 18\u001b[0m, in \u001b[0;36mCXRDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform: \u001b[38;5;66;03m#transform.compose()객체를 받으면 해당 작업들이 들어 있음.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py:2356\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2346\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2347\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2348\u001b[0m         )\n\u001b[1;32m   2349\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2350\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2351\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2352\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2353\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2354\u001b[0m         )\n\u001b[0;32m-> 2356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss() #binary에서 사용? \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"  🔄 Epoch {epoch+1} 시작\")\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        #print(f\"    📦 배치 불러오기 완료\")\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        print(f\"    ✅ forward 완료\")\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(f\"    ✅ loss 계산 완료\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"    ✅ backward 완료, optimizer step 완료\")\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(torch.sigmoid(outputs).cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {train_loss:.4f} | AUROC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f8b2c14-23e4-4fa7-9989-212fa0a9a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17a025c9-62b6-4d1d-9995-5238878e988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1c219-293e-4c1f-9cc7-cdc2316219a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.6 (NGC 25.01/Python 3.12) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
